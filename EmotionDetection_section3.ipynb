{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmotionDetection_section3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wydialang/emotiondetect/blob/master/EmotionDetection_section3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhr-G_92H2Bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceca9db3-687c-49b1-8a5f-1743d64e96de"
      },
      "source": [
        "#@title Run this to download data and prepare our environment!  { display-mode: \"form\" }\n",
        "\n",
        "import cv2\n",
        "import dlib\n",
        "import pickle\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "from sklearn import metrics\n",
        "from scipy.spatial import distance\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm,tqdm_pandas\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import gdown\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "# grab tools from our tensorflow and keras toolboxes!\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import optimizers\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "def model_to_string(model):\n",
        "    import re\n",
        "    stringlist = []\n",
        "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "    sms = \"\\n\".join(stringlist)\n",
        "    sms = re.sub('_\\d\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d','', sms)  \n",
        "    return sms\n",
        "\n",
        "###Getting the csv data loaded\n",
        "\n",
        "dataset_url = 'https://drive.google.com/uc?id=1xFiYsULlQWWmi2Ai0fHjtApniP5Pscuf'\n",
        "dataset_path = './ferdata.csv'\n",
        "gdown.download(dataset_url, dataset_path, True)\n",
        "\n",
        "###Getting the Dlib Shape predictor!\n",
        "\n",
        "dlibshape_url = 'https://drive.google.com/uc?id=17D3D89Gke6i5nKOvmsbPslrGg5rVgOwg'\n",
        "dlibshape_path ='./shape_predictor_68_face_landmarks.dat'\n",
        "gdown.download(dlibshape_url, dlibshape_path, True)\n",
        "\n",
        "###Getting the Xpure loaded\n",
        "\n",
        "pureX_url = 'https://drive.google.com/uc?id=1CglpXodenZVrkaZehLtfykfQv8dcnfO9'\n",
        "pureX_path = './pureX.npy'\n",
        "gdown.download(pureX_url, pureX_path,True)\n",
        "\n",
        "###Getting the Xdata loaded\n",
        "\n",
        "dataX_url = 'https://drive.google.com/uc?id=1sIJGxUM6rNBcWxucs6iynDepeKU1Q56p'\n",
        "dataX_path = './dataX.npy'\n",
        "gdown.download(dataX_url, dataX_path, True)\n",
        "\n",
        "\n",
        "###Getting the Ydata loaded\n",
        "\n",
        "dataY_url = 'https://drive.google.com/uc?id=1Rfr0OP-hZO_UZfuOyMNR2RjNRAro85zE'\n",
        "dataY_path = './dataY.npy'\n",
        "gdown.download(dataY_url, dataY_path, True)\n",
        "\n",
        "\n",
        "print (\"Data Downloaded!\")\n",
        "\n",
        "\n",
        "'''\n",
        "Plots the confusion Matrix and saves it\n",
        "'''\n",
        "def plot_confusion_matrix(y_true,y_predicted):\n",
        "  cm = metrics.confusion_matrix(y_true, y_predicted)\n",
        "  print (\"Plotting the Confusion Matrix\")\n",
        "  labels = list(label_map.values())\n",
        "  df_cm = pd.DataFrame(cm,index = labels,columns = labels)\n",
        "  fig = plt.figure()\n",
        "  res = sns.heatmap(df_cm, annot=True,cmap='Blues', fmt='g')\n",
        "  plt.yticks([0.5,1.5,2.5,3.5,4.5], labels,va='center')\n",
        "  plt.title('Confusion Matrix - TestData')\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        " \n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def plot_graphs(history, best):\n",
        "  \n",
        "  plt.figure(figsize=[10,4])\n",
        "  # summarize history for accuracy\n",
        "  plt.subplot(121)\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy across training\\n best accuracy of %.02f'%best[1])\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.subplot(122)\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss across training\\n best loss of %.02f'%best[0])\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "#Integer to Label Mapping\n",
        "label_map = {\"0\":\"ANGRY\",\"1\":\"HAPPY\",\"2\":\"SAD\",\"3\":\"SURPRISE\",\"4\":\"NEUTRAL\"}\n",
        "\n",
        "\n",
        "#Load the 68 face Landmark file\n",
        "predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')\n",
        "\"\"\"\n",
        "Returns facial landmarks for the given input image path\n",
        "\"\"\"\n",
        "def get_landmarks(image):\n",
        "  \n",
        "  \n",
        "  #:type image : cv2 object\n",
        "  #:rtype landmarks : list of tuples where each tuple represents \n",
        "  #                  the x and y co-ordinates of facial keypoints\n",
        "  \n",
        "  #Bounding Box co-ordinates around the face(Training data is 48*48(cropped faces))\n",
        "  rects = [dlib.rectangle(left=1, top=1, right=47, bottom=47)]\n",
        "\n",
        "  #Read Image using OpenCV\n",
        "  #image = cv2.imread(image_path)\n",
        "  #Detect the Faces within the image\n",
        "  landmarks = [(p.x, p.y) for p in predictor(image, rects[0]).parts()]\n",
        "  return image,landmarks\n",
        "\n",
        "\"\"\"\n",
        "Display image with its Facial Landmarks\n",
        "\"\"\"\n",
        "def image_landmarks(image,face_landmarks):\n",
        "  \"\"\"\n",
        "  :type image_path : str\n",
        "  :type face_landmarks : list of tuples where each tuple represents \n",
        "                     the x and y co-ordinates of facial keypoints\n",
        "  :rtype : None\n",
        "  \"\"\"\n",
        "  radius = -4\n",
        "  circle_thickness = 1\n",
        "  image_copy = image.copy()\n",
        "  for (x, y) in face_landmarks:\n",
        "    cv2.circle(image_copy, (x, y), circle_thickness, (255,0,0), radius)\n",
        "    \n",
        "  plt.imshow(image_copy, interpolation='nearest')\n",
        "  plt.show()\n",
        "  \n",
        "\"\"\"\n",
        "Computes euclidean distance between 68 Landmark Points for our features\n",
        "e_dist is a list of features that will go into our model.\n",
        "Each feature is a distance between two landmark points, and every pair of points\n",
        "must have a feature.\n",
        "\"\"\"\n",
        "  \n",
        "def landmarks_edist(face_landmarks):\n",
        "    e_dist = []\n",
        "    for i in range(len(face_landmarks)):\n",
        "        for j in range(len(face_landmarks)):\n",
        "            if i!= j:\n",
        "                e_dist.append(distance.euclidean(face_landmarks[i],face_landmarks[j]))\n",
        "    return e_dist\n",
        "  \n",
        "def compare_learning(mlp, lm, cnn, vgg): # there's one model missing: MLP from pixels\n",
        "  \n",
        "  # summarize history for accuracy\n",
        "  plt.plot(vgg.history['val_accuracy'],)\n",
        "  plt.plot(cnn.history['val_accuracy'])\n",
        "  plt.plot(mlp.history['val_accuracy'],)\n",
        "  plt.plot(lm.history['val_accuracy'])\n",
        "  plt.ylabel('validitation accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['cnn_transfer', 'cnn_scratch', 'mlp_pixels', 'mlp_landmarks'], bbox_to_anchor=[1,1])\n",
        "  plt.xticks(range(0, epochs+1, 5), range(0, epochs+1, 5))\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Downloaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq10yh_OuVlg",
        "colab_type": "text"
      },
      "source": [
        "#Understanding and building Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOfhabJ_4hvE",
        "colab_type": "text"
      },
      "source": [
        "A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. Basically, neural network algorithm helps computers think and learn like humans.\n",
        "\n",
        "The whole idea of artificial neural network is based on the concept of the structure and functions of a human brain. A human brain consists of neurons that process and transmit information between themselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DcLenvXu7th",
        "colab_type": "text"
      },
      "source": [
        "### Why try neural networks?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s77Fm2CbvZi7",
        "colab_type": "text"
      },
      "source": [
        "Our Baseline model performed at ~50 %\n",
        "\n",
        "Human accuracy for fer2013 is around 65 %, suggesting that we could do better!\n",
        "\n",
        "What we require now is a model that can capture more complicated patterns. One class of models that is able to do this and has been very effective for doing this for images are neural networks. \n",
        "\n",
        "\n",
        "### What are neural networks?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB_uPibnv2UG",
        "colab_type": "text"
      },
      "source": [
        "## Instructor-Led Discussion: Building networks\n",
        "\n",
        "To build neural networks in Python, we use the packages known as `tensorflow` and `keras`. Let's learn how to build and use these networks!\n",
        "\n",
        "Tensorflow calls the various machine learning algorithms that it uses 'models'.  These 'models' are 'learning machines.''\n",
        "\n",
        "1. We **teach** models by **training** them on **data**. \n",
        "2. We **use** models to **predict** things. \n",
        "\n",
        "Here is example code for building a Tensorflow model with Keras:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUtJ7_FkkPr-",
        "colab_type": "text"
      },
      "source": [
        "The things you'll want to pay most attention to as we go over how to build networks are: \n",
        "1. The number of neurons\n",
        "2. The activation of the neurons\n",
        "3. The losses and metrics\n",
        "\n",
        "Everything else will work with the default settings!\n",
        "\n",
        "Let's walk though what each of these lines of code means!\n",
        "\n",
        "**1. Specify model**\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "```\n",
        "In this line of code, we build our network where the information flows from LEFT to RIGHT through the network in ONE DIRECTION as opposed to multiple directions. Neurons on the right never pass informations to neurons on the left of it. \n",
        "\n",
        "\n",
        "**2. Add layers to the network**\n",
        "```\n",
        "model.add(Dense(4,input_shape = (3,), activation = 'sigmoid'))\n",
        "```\n",
        "In this code, we `add` a `layer` of neurons to our network. \n",
        "\n",
        "This layers consists of 4 neurons. Each neuron is DENSE and connects to all of the previous layer's inputs and all of the subsequent layers outputs. We specify that there are 3 inputs here.\n",
        "\n",
        "We also specify what kind of output the neuron will give. If you want the neuron to output a number between 0 and 1 (like a probability!) you would use 'softmax' or 'sigmoid'. If you want the neuron to output any number, you can use 'linear'! You'll also often see 'relu', which is when a neuron will only output positive numbers. \n",
        "\n",
        "```\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "```\n",
        "This code adds ANOTHER layer to the network that has 1 neuron. This one neuron is used to predict a continuous value!\n",
        "\n",
        "\n",
        "**3. Turn the model on by compiling it** \n",
        "\n",
        "After having built the network, we want to train and use it, so we have to 'turn it on' and 'compile' it. To turn it on, we have to specify at the very least, a loss, an optimizer, and some ways of evaluating the model (metrics). Don't worry too much about what this means! Just know that this is necessary. \n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error',\n",
        "optimizer = 'adam',\n",
        "metrics = ['mean_squared_error'])\n",
        "  ```\n",
        "  \n",
        "  Once we've created our network, we can use it very simply! Just like we did with sklearn, we define our input data (x), the true predictions from that data (y), and then train our model with `fit`. \n",
        "\n",
        "```\n",
        "model.fit(x, y)\n",
        "```\n",
        "\n",
        "To use the model, you can use it to predict something with:\n",
        "```\n",
        "y = model.predict_classes(x)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrW6KxLy8Ox3",
        "colab_type": "text"
      },
      "source": [
        "### For reference, this is a lot like the kind of models we've been training with scikit learn.\n",
        "\n",
        "The big difference is that defining the model is more involved. We can look at an example from KNN: \n",
        "\n",
        "```\n",
        "# define the model instance \n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# train model with X_train\n",
        "knn.fit(X_train, y_train) \n",
        "\n",
        "# predict testing data\n",
        "y_predict = knn.predict(X_test)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJXxWYXcwoGn",
        "colab_type": "text"
      },
      "source": [
        "##Exercise: Coding a 2 hidden layer MLP\n",
        "\n",
        "\n",
        "Just as we went over last week, neural networks look something like this: \n",
        "\n",
        "\n",
        "![A 2 layer neural network](https://cdn-images-1.medium.com/max/1600/1*DW0Ccmj1hZ0OvSXi7Kz5MQ.jpeg)\n",
        "\n",
        "\n",
        "Each orange and blue node is a neuron. The network itself is composed of a bunch of neurons that talk to each other and eventually give us a prediction. Let's get a bit more concrete with this..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MamYyRf16Ii",
        "colab_type": "text"
      },
      "source": [
        "### How can we build this network above? Fill in the ___ 's below "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1FadMwUkOwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, we initialize our model\n",
        "tmp_model = Sequential()\n",
        "# then we add a \"Dense\" (i.e. fully connected) layer\n",
        "tmp_model.add(Dense(7, input_shape=(5,), activation = 'relu')) # for the first layer we specify the input dimensions \n",
        "# then we have to add another layer \n",
        "tmp_model.add(Dense(7, activation = 'relu'))\n",
        "# we end by defining the output layer, which has the number of dimensions of the predictions we're making\n",
        "tmp_model.add(Dense(4, activation = 'linear'))\n",
        "# we finalize the model by \"compiling\" it and defining some other hyperparameters \n",
        "tmp_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rrqPkJWVLOY",
        "colab_type": "text"
      },
      "source": [
        "## Exercise: Building our custom neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25DoFvA0VWnq",
        "colab_type": "text"
      },
      "source": [
        "###Keypoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tchJVYOTVZAh",
        "colab_type": "text"
      },
      "source": [
        "We will build a simple 3-layer network for our first model!\n",
        "\n",
        "\n",
        "For our model, we have as our layers: \n",
        "* Input Layer:  However many inputs there are!\n",
        "* Layer 1 (Hidden): 1024 neurons that are activated by `'relu'` and weights are intialized using '`kernel_initializer='glorot_normal'`. Specify the input shape as `(4556,)`.\n",
        "* Layer 2 (Hidden): 512 neurons that are activated by `'relu'` and weights are intialized using '`kernel_initializer='glorot_normal'`\n",
        "* Layer 3 (Output): 5 neuron that should have an appropriate activation. \n",
        "* We will compile with the `optimizers.SGD(lr=0.001)` optimizer\n",
        "\n",
        "As a hint for the output activation and the compilation loss, we know that:\n",
        "* Multi-class classification problems require an output activation of `'softmax'` and a loss of `'categorical_crossentropy'`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3U4FxbVyfs",
        "colab_type": "text"
      },
      "source": [
        "###Build your Model (call it `perceptron`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJh4klMtV3Q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "perceptron = Sequential()\n",
        "perceptron.add(Dense(1024, input_shape=(4556,), activation = 'relu', kernel_initializer='glorot_normal'))\n",
        "perceptron.add(Dense(512, activation = 'relu', kernel_initializer='glorot_normal'))\n",
        "perceptron.add(Dense(5, activation = 'softmax'))\n",
        "perceptron.compile(loss='categorical_crossentropy', optimizer = optimizers.SGD(lr=0.001), metrics=['accuracy'])\n",
        "\n",
        "# END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWDzNTh9Wm0e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f076899-8baf-43bf-af5c-406622d02919"
      },
      "source": [
        " #@title Run this to test if your model is right! { display-mode: \"form\" }\n",
        "perceptron_answer = Sequential()\n",
        "perceptron_answer.add(Dense(units = 1024, input_shape = (4556,),kernel_initializer='glorot_normal',activation = 'relu'))\n",
        "perceptron_answer.add(Dense(units = 512,kernel_initializer='glorot_normal' , activation = 'relu'))\n",
        "perceptron_answer.add(Dense(units = 5, activation = 'softmax'))\n",
        "    \n",
        "perceptron_answer.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "if model_to_string(perceptron) == model_to_string(perceptron_answer):\n",
        "  print('Good job, you specified it correctly!')\n",
        "else: \n",
        "  print('Please check your code again!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Good job, you specified it correctly!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bbdW8Cm-iti",
        "colab_type": "text"
      },
      "source": [
        "###Keras Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgQEGSXJueyV",
        "colab_type": "text"
      },
      "source": [
        "Neural Network performance depends a lot on *how much* they train. As we'll see, they usually get better with more training BUT actually can get worse with too much training. With too much training, our model can get overconfident in its abilities with the training manual (overfitting), and so doesn't actually think (generalize) when it is tested. \n",
        "\n",
        "The  `fit()` function pertain to how the neural networks train. Don't worry too much about the extra options, what really matters for us is that the right data is specified.\n",
        "\n",
        "\n",
        "What are all these options?\n",
        "* `epochs`: how many times the model trains on the entire data set\n",
        "* `batch_size`: number of samples processed at a time\n",
        "* `shuffle`: mixes the training dataset so the model pays better attention to the data and learns better while training\n",
        "* `validation_data`: we request that our model tests itself on the `test_data` after every epoch. **It is essential to use validation data to test for overfitting!**\n",
        "* `callbacks`: With a custom command, we tell our model to save the best version of itself to a model file called `best_dnn_model.h5`. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeb1iFnZw3W1",
        "colab_type": "text"
      },
      "source": [
        "#Applying Neural Networks (MLPs) to predicting emotions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf4GspMjAGoE",
        "colab_type": "text"
      },
      "source": [
        "First, let's try to build a 4-Layer Neural Network  for our training data to achieve accuracy closer to the human accuracy on the dataset (around 65%)\n",
        "\n",
        "\n",
        " We want to identify the key things that we need to design our network. \n",
        "\n",
        "In your group, discuss: \n",
        "\n",
        "* What are our inputs?\n",
        "* What is/are our outputs?\n",
        "\n",
        "How could this look in a neural network diagram?\n",
        "\n",
        "**Show your instructor your diagram once you're done!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-hJkIeQthKl",
        "colab_type": "text"
      },
      "source": [
        "##Activity: Train Neural Network on Emotion Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDZqO4EMHeSZ",
        "colab_type": "text"
      },
      "source": [
        "###Set some hyper parameters for all models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "284_6dNsHiS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the number of times we pass all the training data through the model \n",
        "epochs = 20\n",
        "# the number of examples we pass to the model at each time\n",
        "batch_size = 64\n",
        "# the proportion of testing data we set aside (e.g. 10%)\n",
        "test_ratio = .1\n",
        "# the number of emotion categories we have to predict\n",
        "n_labels = 5 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNJx9QCE8w8p",
        "colab_type": "text"
      },
      "source": [
        "###Load the original (unprocessed) data saved on Day 2!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG7AIjf3xWBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data \n",
        "dataX_pixels = np.load('pureX.npy')\n",
        "dataY_pixels = np.load('dataY.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y6HwMAg85jx",
        "colab_type": "text"
      },
      "source": [
        "### Convert labels to one-hot encoded labels\n",
        "\n",
        "One hot encoding is a representation of categorical variables as binary vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA_0acGq9AJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert labels to one hot encoding\n",
        "y_onehot = keras.utils.to_categorical(dataY_pixels, len(set(dataY_pixels)))\n",
        "\n",
        "# what does this data type look like? "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-LTjtaknAqa",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Is it clear how these are to equavalent ways to represent the target?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RodV9eQ71Yz",
        "colab_type": "text"
      },
      "source": [
        "###Split and Standardize your Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVO4wnTY7rRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split Data into Train, Test (90-10)\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataX_pixels, y_onehot, test_size=test_ratio, random_state=42)\n",
        "\n",
        "#### Standardize the data ##########\n",
        "pixel_scaler = StandardScaler()\n",
        "pixel_scaler.fit(X_train)\n",
        "X_train = pixel_scaler.transform(X_train)\n",
        "X_test = pixel_scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaQQkwNsHGSM",
        "colab_type": "text"
      },
      "source": [
        "## Exercise: Build a simple MLP for emotion detection (call it `mlp_model`)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBk3kFJSgQJ0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#YOUR CODE HERE\n",
        "mlp_model = Sequential()\n",
        "mlp_model.add(Dense(1024, input_shape=(X_train.shape[1],), activation = 'relu', kernel_initializer='glorot_normal'))\n",
        "mlp_model.add(Dense(512, activation = 'relu', kernel_initializer='glorot_normal'))\n",
        "mlp_model.add(Dense(5, activation = 'softmax'))\n",
        "\n",
        "\n",
        "#END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwYofcaXzWVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1502f35d-eae1-4325-8e04-95a409030dc3"
      },
      "source": [
        "# Compiling the model with SGD optimixer and categorical crossentropy loss\n",
        "mlp_model.compile(loss=categorical_crossentropy, optimizer=SGD(lr=0.001), metrics=['accuracy'])\n",
        "              \n",
        "#Saves the Best Model Based on Val Loss\n",
        "checkpoint = ModelCheckpoint('best_mlp_model.h5', verbose=1, monitor='val_accuracy', save_best_only=True,  mode='auto')  \n",
        "\n",
        "#training the model\n",
        "mlp_history = mlp_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \n",
        "                            callbacks=[checkpoint], validation_data=(X_test, y_test), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "282/282 [==============================] - ETA: 0s - loss: 1.6166 - accuracy: 0.2793\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.30300, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.6166 - accuracy: 0.2793 - val_loss: 1.5605 - val_accuracy: 0.3030\n",
            "Epoch 2/20\n",
            "278/282 [============================>.] - ETA: 0s - loss: 1.4848 - accuracy: 0.3553\n",
            "Epoch 00002: val_accuracy improved from 0.30300 to 0.34200, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.4846 - accuracy: 0.3558 - val_loss: 1.5068 - val_accuracy: 0.3420\n",
            "Epoch 3/20\n",
            "265/282 [===========================>..] - ETA: 0s - loss: 1.4332 - accuracy: 0.3911\n",
            "Epoch 00003: val_accuracy improved from 0.34200 to 0.36900, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.4315 - accuracy: 0.3922 - val_loss: 1.4758 - val_accuracy: 0.3690\n",
            "Epoch 4/20\n",
            "266/282 [===========================>..] - ETA: 0s - loss: 1.3937 - accuracy: 0.4185\n",
            "Epoch 00004: val_accuracy improved from 0.36900 to 0.38050, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.3961 - accuracy: 0.4179 - val_loss: 1.4547 - val_accuracy: 0.3805\n",
            "Epoch 5/20\n",
            "279/282 [============================>.] - ETA: 0s - loss: 1.3682 - accuracy: 0.4344\n",
            "Epoch 00005: val_accuracy improved from 0.38050 to 0.39100, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.3688 - accuracy: 0.4337 - val_loss: 1.4366 - val_accuracy: 0.3910\n",
            "Epoch 6/20\n",
            "282/282 [==============================] - ETA: 0s - loss: 1.3462 - accuracy: 0.4465\n",
            "Epoch 00006: val_accuracy improved from 0.39100 to 0.39350, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.3462 - accuracy: 0.4465 - val_loss: 1.4243 - val_accuracy: 0.3935\n",
            "Epoch 7/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 1.3266 - accuracy: 0.4596\n",
            "Epoch 00007: val_accuracy improved from 0.39350 to 0.40250, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.3264 - accuracy: 0.4597 - val_loss: 1.4132 - val_accuracy: 0.4025\n",
            "Epoch 8/20\n",
            "268/282 [===========================>..] - ETA: 0s - loss: 1.3098 - accuracy: 0.4714\n",
            "Epoch 00008: val_accuracy improved from 0.40250 to 0.40500, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.3084 - accuracy: 0.4720 - val_loss: 1.4070 - val_accuracy: 0.4050\n",
            "Epoch 9/20\n",
            "274/282 [============================>.] - ETA: 0s - loss: 1.2932 - accuracy: 0.4786\n",
            "Epoch 00009: val_accuracy improved from 0.40500 to 0.41000, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.2931 - accuracy: 0.4786 - val_loss: 1.4007 - val_accuracy: 0.4100\n",
            "Epoch 10/20\n",
            "271/282 [===========================>..] - ETA: 0s - loss: 1.2777 - accuracy: 0.4867\n",
            "Epoch 00010: val_accuracy improved from 0.41000 to 0.41800, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.2776 - accuracy: 0.4867 - val_loss: 1.3932 - val_accuracy: 0.4180\n",
            "Epoch 11/20\n",
            "271/282 [===========================>..] - ETA: 0s - loss: 1.2643 - accuracy: 0.4947\n",
            "Epoch 00011: val_accuracy improved from 0.41800 to 0.42150, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.2645 - accuracy: 0.4946 - val_loss: 1.3855 - val_accuracy: 0.4215\n",
            "Epoch 12/20\n",
            "269/282 [===========================>..] - ETA: 0s - loss: 1.2511 - accuracy: 0.5005\n",
            "Epoch 00012: val_accuracy improved from 0.42150 to 0.42800, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.2508 - accuracy: 0.5012 - val_loss: 1.3823 - val_accuracy: 0.4280\n",
            "Epoch 13/20\n",
            "276/282 [============================>.] - ETA: 0s - loss: 1.2404 - accuracy: 0.5059\n",
            "Epoch 00013: val_accuracy did not improve from 0.42800\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.2392 - accuracy: 0.5069 - val_loss: 1.3744 - val_accuracy: 0.4230\n",
            "Epoch 14/20\n",
            "275/282 [============================>.] - ETA: 0s - loss: 1.2274 - accuracy: 0.5152\n",
            "Epoch 00014: val_accuracy improved from 0.42800 to 0.43400, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.2270 - accuracy: 0.5159 - val_loss: 1.3721 - val_accuracy: 0.4340\n",
            "Epoch 15/20\n",
            "275/282 [============================>.] - ETA: 0s - loss: 1.2161 - accuracy: 0.5189\n",
            "Epoch 00015: val_accuracy improved from 0.43400 to 0.43500, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.2155 - accuracy: 0.5195 - val_loss: 1.3655 - val_accuracy: 0.4350\n",
            "Epoch 16/20\n",
            "278/282 [============================>.] - ETA: 0s - loss: 1.2042 - accuracy: 0.5275\n",
            "Epoch 00016: val_accuracy did not improve from 0.43500\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 1.2043 - accuracy: 0.5277 - val_loss: 1.3606 - val_accuracy: 0.4305\n",
            "Epoch 17/20\n",
            "274/282 [============================>.] - ETA: 0s - loss: 1.1937 - accuracy: 0.5340\n",
            "Epoch 00017: val_accuracy improved from 0.43500 to 0.43800, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.1938 - accuracy: 0.5338 - val_loss: 1.3613 - val_accuracy: 0.4380\n",
            "Epoch 18/20\n",
            "282/282 [==============================] - ETA: 0s - loss: 1.1838 - accuracy: 0.5384\n",
            "Epoch 00018: val_accuracy did not improve from 0.43800\n",
            "282/282 [==============================] - 1s 3ms/step - loss: 1.1838 - accuracy: 0.5384 - val_loss: 1.3561 - val_accuracy: 0.4350\n",
            "Epoch 19/20\n",
            "278/282 [============================>.] - ETA: 0s - loss: 1.1734 - accuracy: 0.5436\n",
            "Epoch 00019: val_accuracy improved from 0.43800 to 0.43900, saving model to best_mlp_model.h5\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.1736 - accuracy: 0.5434 - val_loss: 1.3546 - val_accuracy: 0.4390\n",
            "Epoch 20/20\n",
            "266/282 [===========================>..] - ETA: 0s - loss: 1.1647 - accuracy: 0.5488\n",
            "Epoch 00020: val_accuracy did not improve from 0.43900\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 1.1635 - accuracy: 0.5497 - val_loss: 1.3471 - val_accuracy: 0.4380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF0MmGV8Lm7y",
        "colab_type": "text"
      },
      "source": [
        "##Neural Network Model Evaluation on pixel inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORXi0y71t3o8",
        "colab_type": "text"
      },
      "source": [
        "###Evaluate best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnjfotXoth4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ea65cdd-3108-4fdb-e85c-ae47f4d9cbe2"
      },
      "source": [
        "mlp_performance = mlp_model.evaluate(X_test, y_test, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3471 - accuracy: 0.4380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vgEP7OnGlR9",
        "colab_type": "text"
      },
      "source": [
        "###Visualize accuracy and loss over training + display best model's performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktHNwzn0G73y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "45d6e7ef-9b4d-49d1-d4c2-fb312bed71e7"
      },
      "source": [
        "plot_graphs(mlp_history, mlp_performance); "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPeyL20OFzjN",
        "colab_type": "text"
      },
      "source": [
        "###Plot the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgkxPwg2F7eL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "21b65d2c-85fd-492f-d029-e3ebeab835f1"
      },
      "source": [
        "y_pred_mlp = mlp_model.predict_classes(X_test)\n",
        "y_true = np.argmax(y_test,axis=1)\n",
        "plot_confusion_matrix(y_true, y_pred_mlp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-24-824b937afa04>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "Plotting the Confusion Matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqLIJTjW0JE_",
        "colab_type": "text"
      },
      "source": [
        "##Neural Network Model Evaluation on distance inputs\n",
        "\n",
        "We saw yesterday that building a model on the distances between facial landmarks did better than on raw pixel inputs, is this true for these models as well? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yFQHl8n7Xjd",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#Load the data (Distances between facial Landmarks)\n",
        "dataX_lm = np.load('./dataX.npy')\n",
        "#dataY_lm = np.load('./dataY.npy')\n",
        "\n",
        "# convert labels to one hot encoding\n",
        "#y_onehot = keras.utils.to_categorical(dataY_lm, len(set(dataY_lm)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-aKmK6e0a4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split Data into Train, Test (90-10)\n",
        "X_train_lm, X_test_lm, y_train_lm, y_test_lm = train_test_split(dataX_lm, y_onehot, test_size=0.1, random_state=42)\n",
        "\n",
        "#### Standardize the data ##########\n",
        "lm_scaler = StandardScaler()\n",
        "lm_scaler.fit(X_train_lm)\n",
        "X_train_lm = lm_scaler.transform(X_train_lm)\n",
        "X_test_lm = lm_scaler.transform(X_test_lm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QEUcTxh7Ara",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "746ffd38-a4f6-4ebc-ed9c-0fe8e52b655b"
      },
      "source": [
        "# Compliling the model with SGD optimixer and categorical crossentropy loss\n",
        "lm_model.compile(loss=categorical_crossentropy, optimizer=SGD(lr=0.001), metrics=['accuracy'])\n",
        "\n",
        "#Saves the Best Model Based on Val Loss\n",
        "checkpoint = ModelCheckpoint('best_lm_model.h5', verbose=1, monitor='val_loss',save_best_only=True,  mode='auto')  \n",
        "#training the model\n",
        "lm_history = lm_model.fit(X_train_lm, y_train_lm, batch_size=batch_size, epochs=epochs, \n",
        "                          verbose=1, callbacks=[checkpoint], validation_data=(X_test_lm, y_test_lm), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f7bc3d88ab8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m lm_history = lm_model.fit(X_train_lm, y_train_lm, batch_size=batch_size, epochs=epochs, \n\u001b[0;32m----> 8\u001b[0;31m                           verbose=1, callbacks=[checkpoint], validation_data=(X_test_lm, y_test_lm), shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_10 is incompatible with the layer: expected axis -1 of input shape to have value 2304 but received input with shape [None, 4556]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPub4NX31R3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm_model = Sequential()\n",
        "lm_model.add(Dense(1024, input_shape=(X_train_lm.shape[1],), activation = 'relu', kernel_initializer='glorot_normal'))\n",
        "lm_model.add(Dense(512, activation = 'relu', kernel_initializer='glorot_normal'))\n",
        "lm_model.add(Dense(5, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdViZtbLpCfQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62efe373-c096-4bc9-839e-9645e9fa060b"
      },
      "source": [
        "print(X_train_lm.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18000, 4556)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb2ruZoq1YPO",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBOe-N6NgQag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "0a475de1-10bb-4c1d-92e2-02893936e9b1"
      },
      "source": [
        "lm_performance = lm_model.evaluate(X_train_lm, y_train_lm, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-1c0f73031e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm_performance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_lm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_lm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2567\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2569\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2570\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj3XDT2eu31x",
        "colab_type": "text"
      },
      "source": [
        "###Visualize accuracy and loss over training + display best model's performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG1V_8AIs9Xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xk6GHxUgiY6",
        "colab_type": "text"
      },
      "source": [
        "## Instructor-Led Discussion\n",
        "\n",
        "How can we explain the difference between these two models?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX9zvfvrAtrj",
        "colab_type": "text"
      },
      "source": [
        "#Convolutional Neural Networks for Emotion Detection!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXuDr1x1CZYP",
        "colab_type": "text"
      },
      "source": [
        "###Model Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvPqbBy8Cc1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we'll use the same epochs and batch size as above\n",
        "width, height = 48, 48"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTH-IlrL0HVE",
        "colab_type": "text"
      },
      "source": [
        "###Reshape the inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwTlyCBk6FOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfde5b96-0c6e-49ec-898f-dd779cf16867"
      },
      "source": [
        "# pixels were vectors\n",
        "print(X_train.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18000, 2304)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNSP1-vz6Lnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ce5265b-5e9d-4f71-de6c-191a0c2c5e9e"
      },
      "source": [
        "X_train_cnn = X_train.reshape(len(X_train),height,width)\n",
        "X_test_cnn = X_test.reshape(len(X_test),height,width)\n",
        "\n",
        "# we've converted them to images\n",
        "print(X_train_cnn.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18000, 48, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFP5S57i69o7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c0f95b1-69ec-46e3-80f3-0bfdb328001c"
      },
      "source": [
        "# now we add one more dimension for model compatability\n",
        "X_train_cnn = np.expand_dims(X_train_cnn,3)\n",
        "X_test_cnn = np.expand_dims(X_test_cnn,3)\n",
        "\n",
        "print(X_train_cnn.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18000, 48, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnI75Z1yDylH",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Change the hyperparameters in the model below \n",
        "\n",
        "# initialize model\n",
        "cnn_model = Sequential()\n",
        "# this conv layer has 64 filters! the input shape needs to be the same dimensions of the image\n",
        "cnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1)))\n",
        "# batch normalization \n",
        "cnn_model.add(BatchNormalization())\n",
        "# max pooling\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "# dropout\n",
        "cnn_model.add(Dropout(0.5))\n",
        "\n",
        "# flatten all the outputs between convolutional and dense layers\n",
        "cnn_model.add(Flatten())\n",
        "# add a \"dense layer\" (i.e. the fully connected layers in MLPs) with dropout\n",
        "cnn_model.add(Dense(512, activation='relu'))\n",
        "# output layer\n",
        "cnn_model.add(Dense(n_labels, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtRf96cBdcom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#YOUR CODE HERE\n",
        "#YOUR CODE HERE\n",
        "#YOUR CODE HERE\n",
        "#YOUR CODE HERE\n",
        "############### CALL YOUR MODEL 'cnn_model' \n",
        "#YOUR CODE HERE\n",
        "#YOUR CODE HERE\n",
        "#YOUR CODE HERE\n",
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqirnWL8wDGR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63d2e79d-7503-4ee7-b49d-92ea2845e8a8"
      },
      "source": [
        "#Saves the Best Model Based on Val Loss\n",
        "checkpoint = ModelCheckpoint('best_cnn_model.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
        "\n",
        "# compliling the model with adam optimixer and categorical crossentropy loss\n",
        "cnn_model.compile(loss=categorical_crossentropy, optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999), metrics=['accuracy'])\n",
        "\n",
        "# training the model\n",
        "cnn_history = cnn_model.fit(X_train_cnn, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \n",
        "                            callbacks=[checkpoint], validation_data=(X_test_cnn, y_test), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "280/282 [============================>.] - ETA: 0s - loss: 2.4239 - accuracy: 0.4055\n",
            "Epoch 00001: val_loss improved from inf to 1.46744, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 2.4187 - accuracy: 0.4057 - val_loss: 1.4674 - val_accuracy: 0.4285\n",
            "Epoch 2/20\n",
            "280/282 [============================>.] - ETA: 0s - loss: 1.1751 - accuracy: 0.5223\n",
            "Epoch 00002: val_loss improved from 1.46744 to 1.22630, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 1.1752 - accuracy: 0.5222 - val_loss: 1.2263 - val_accuracy: 0.5055\n",
            "Epoch 3/20\n",
            "280/282 [============================>.] - ETA: 0s - loss: 1.0305 - accuracy: 0.5879\n",
            "Epoch 00003: val_loss improved from 1.22630 to 1.20386, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 4s 14ms/step - loss: 1.0311 - accuracy: 0.5877 - val_loss: 1.2039 - val_accuracy: 0.5215\n",
            "Epoch 4/20\n",
            "278/282 [============================>.] - ETA: 0s - loss: 0.8993 - accuracy: 0.6471\n",
            "Epoch 00004: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.8989 - accuracy: 0.6473 - val_loss: 1.2819 - val_accuracy: 0.5335\n",
            "Epoch 5/20\n",
            "280/282 [============================>.] - ETA: 0s - loss: 0.7773 - accuracy: 0.6964\n",
            "Epoch 00005: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.7776 - accuracy: 0.6964 - val_loss: 1.3967 - val_accuracy: 0.5295\n",
            "Epoch 6/20\n",
            "280/282 [============================>.] - ETA: 0s - loss: 0.6670 - accuracy: 0.7458\n",
            "Epoch 00006: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 4s 13ms/step - loss: 0.6674 - accuracy: 0.7458 - val_loss: 1.3532 - val_accuracy: 0.5375\n",
            "Epoch 7/20\n",
            "280/282 [============================>.] - ETA: 0s - loss: 0.5413 - accuracy: 0.7958\n",
            "Epoch 00007: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 4s 12ms/step - loss: 0.5417 - accuracy: 0.7957 - val_loss: 1.5552 - val_accuracy: 0.5340\n",
            "Epoch 8/20\n",
            "279/282 [============================>.] - ETA: 0s - loss: 0.4581 - accuracy: 0.8311\n",
            "Epoch 00008: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 4s 13ms/step - loss: 0.4590 - accuracy: 0.8305 - val_loss: 1.6315 - val_accuracy: 0.5420\n",
            "Epoch 9/20\n",
            "278/282 [============================>.] - ETA: 0s - loss: 0.3801 - accuracy: 0.8599\n",
            "Epoch 00009: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 4s 13ms/step - loss: 0.3800 - accuracy: 0.8598 - val_loss: 1.7956 - val_accuracy: 0.5270\n",
            "Epoch 10/20\n",
            "282/282 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.8834\n",
            "Epoch 00010: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 4s 13ms/step - loss: 0.3149 - accuracy: 0.8834 - val_loss: 1.8459 - val_accuracy: 0.5430\n",
            "Epoch 11/20\n",
            "280/282 [============================>.] - ETA: 0s - loss: 0.2945 - accuracy: 0.8951\n",
            "Epoch 00011: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.2949 - accuracy: 0.8951 - val_loss: 1.6679 - val_accuracy: 0.5270\n",
            "Epoch 12/20\n",
            "279/282 [============================>.] - ETA: 0s - loss: 0.2699 - accuracy: 0.9056\n",
            "Epoch 00012: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.2705 - accuracy: 0.9055 - val_loss: 1.8638 - val_accuracy: 0.5425\n",
            "Epoch 13/20\n",
            "282/282 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.9159\n",
            "Epoch 00013: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.2377 - accuracy: 0.9159 - val_loss: 2.0906 - val_accuracy: 0.5440\n",
            "Epoch 14/20\n",
            "278/282 [============================>.] - ETA: 0s - loss: 0.2172 - accuracy: 0.9249\n",
            "Epoch 00014: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.2173 - accuracy: 0.9248 - val_loss: 1.9622 - val_accuracy: 0.5360\n",
            "Epoch 15/20\n",
            "278/282 [============================>.] - ETA: 0s - loss: 0.1927 - accuracy: 0.9341\n",
            "Epoch 00015: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.1929 - accuracy: 0.9342 - val_loss: 2.3035 - val_accuracy: 0.5540\n",
            "Epoch 16/20\n",
            "279/282 [============================>.] - ETA: 0s - loss: 0.1585 - accuracy: 0.9448\n",
            "Epoch 00016: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.1589 - accuracy: 0.9448 - val_loss: 2.2188 - val_accuracy: 0.5330\n",
            "Epoch 17/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.1755 - accuracy: 0.9416\n",
            "Epoch 00017: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.1755 - accuracy: 0.9416 - val_loss: 2.2520 - val_accuracy: 0.5515\n",
            "Epoch 18/20\n",
            "282/282 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.9492\n",
            "Epoch 00018: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.1489 - accuracy: 0.9492 - val_loss: 2.3594 - val_accuracy: 0.5425\n",
            "Epoch 19/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.1385 - accuracy: 0.9532\n",
            "Epoch 00019: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 3s 12ms/step - loss: 0.1384 - accuracy: 0.9533 - val_loss: 2.5846 - val_accuracy: 0.5485\n",
            "Epoch 20/20\n",
            "278/282 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.9587\n",
            "Epoch 00020: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 4s 12ms/step - loss: 0.1264 - accuracy: 0.9586 - val_loss: 2.6156 - val_accuracy: 0.5560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXprpaHpxVb-",
        "colab_type": "text"
      },
      "source": [
        "###Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvCbnwZ_CBYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDmHi_05BKnr",
        "colab_type": "text"
      },
      "source": [
        "###Plot Accuracy and Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdRZz5w2ixwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzLSZVH0jdG0",
        "colab_type": "text"
      },
      "source": [
        "## Instructor-Led Discussion\n",
        "\n",
        "How does this model compare with the others? Did this perform as well as we wanted it to? What might be some of the reasons why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eqKTSlRmEGF",
        "colab_type": "text"
      },
      "source": [
        "#Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPpE58jJmIdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d441b9ea-b4cd-4d98-b326-c966b14404a9"
      },
      "source": [
        "#@title Run this to build your transfer learning model { display-mode: \"form\" }\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.optimizers as optimizers\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "# load the vgg network that is an 'expert' at 'imagenet' but do not include the FC layers\n",
        "vgg_expert = VGG16(weights = 'imagenet', include_top = False, input_shape = (48, 48, 3))\n",
        "\n",
        "# we add the first 12 layers of vgg to our own model vgg_model\n",
        "vgg_model = Sequential()\n",
        "vgg_model.add(vgg_expert)\n",
        "\n",
        "# and then add our own layers on top of it\n",
        "vgg_model.add(GlobalAveragePooling2D())\n",
        "vgg_model.add(Dense(1024, activation = 'relu'))\n",
        "vgg_model.add(Dropout(0.3))\n",
        "vgg_model.add(Dense(512, activation = 'relu'))\n",
        "vgg_model.add(Dropout(0.3))\n",
        "vgg_model.add(Dense(5, activation = 'sigmoid'))\n",
        "\n",
        "# finally, we build the vgg model and turn it on so we can use it!\n",
        "vgg_model.compile(loss = 'categorical_crossentropy', \n",
        "          optimizer = optimizers.SGD(lr=1e-4, momentum=0.95), \n",
        "          metrics=['accuracy'])\n",
        "\n",
        "X_TRAIN = np.array([np.transpose(np.array([X_train_cnn[ix].squeeze() for i in range(3)]), (1,2,0)) for ix in range(len(X_train))])\n",
        "X_TEST = np.array([np.transpose(np.array([X_test_cnn[ix].squeeze() for i in range(3)]), (1,2,0)) for ix in range(len(X_test))])\n",
        "\n",
        "#training the model\n",
        "vgg_history = vgg_model.fit(X_TRAIN, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          callbacks=[checkpoint],\n",
        "          validation_data=(X_TEST, y_test),\n",
        "          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/20\n",
            "  2/282 [..............................] - ETA: 8s - loss: 1.7199 - accuracy: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0213s vs `on_train_batch_end` time: 0.0377s). Check your callbacks.\n",
            "282/282 [==============================] - ETA: 0s - loss: 1.5440 - accuracy: 0.2938\n",
            "Epoch 00001: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 18s 65ms/step - loss: 1.5440 - accuracy: 0.2938 - val_loss: 1.3695 - val_accuracy: 0.4260\n",
            "Epoch 2/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 1.3182 - accuracy: 0.4369\n",
            "Epoch 00002: val_loss did not improve from 1.20386\n",
            "282/282 [==============================] - 18s 63ms/step - loss: 1.3181 - accuracy: 0.4370 - val_loss: 1.2063 - val_accuracy: 0.5005\n",
            "Epoch 3/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 1.1897 - accuracy: 0.5094\n",
            "Epoch 00003: val_loss improved from 1.20386 to 1.07688, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 18s 64ms/step - loss: 1.1896 - accuracy: 0.5093 - val_loss: 1.0769 - val_accuracy: 0.5675\n",
            "Epoch 4/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 1.0868 - accuracy: 0.5578\n",
            "Epoch 00004: val_loss improved from 1.07688 to 0.99204, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 18s 64ms/step - loss: 1.0866 - accuracy: 0.5578 - val_loss: 0.9920 - val_accuracy: 0.6055\n",
            "Epoch 5/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 1.0212 - accuracy: 0.5877\n",
            "Epoch 00005: val_loss improved from 0.99204 to 0.98590, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 18s 64ms/step - loss: 1.0214 - accuracy: 0.5875 - val_loss: 0.9859 - val_accuracy: 0.5990\n",
            "Epoch 6/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.9708 - accuracy: 0.6147\n",
            "Epoch 00006: val_loss improved from 0.98590 to 0.95989, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 18s 64ms/step - loss: 0.9708 - accuracy: 0.6147 - val_loss: 0.9599 - val_accuracy: 0.6010\n",
            "Epoch 7/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.9279 - accuracy: 0.6322\n",
            "Epoch 00007: val_loss improved from 0.95989 to 0.90392, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 18s 64ms/step - loss: 0.9278 - accuracy: 0.6322 - val_loss: 0.9039 - val_accuracy: 0.6365\n",
            "Epoch 8/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.8920 - accuracy: 0.6482\n",
            "Epoch 00008: val_loss improved from 0.90392 to 0.88212, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 18s 64ms/step - loss: 0.8924 - accuracy: 0.6482 - val_loss: 0.8821 - val_accuracy: 0.6420\n",
            "Epoch 9/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.8626 - accuracy: 0.6598\n",
            "Epoch 00009: val_loss did not improve from 0.88212\n",
            "282/282 [==============================] - 18s 63ms/step - loss: 0.8625 - accuracy: 0.6598 - val_loss: 0.9573 - val_accuracy: 0.6290\n",
            "Epoch 10/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.8313 - accuracy: 0.6730\n",
            "Epoch 00010: val_loss improved from 0.88212 to 0.85490, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 18s 64ms/step - loss: 0.8310 - accuracy: 0.6732 - val_loss: 0.8549 - val_accuracy: 0.6550\n",
            "Epoch 11/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.7969 - accuracy: 0.6894\n",
            "Epoch 00011: val_loss did not improve from 0.85490\n",
            "282/282 [==============================] - 18s 63ms/step - loss: 0.7968 - accuracy: 0.6893 - val_loss: 0.8713 - val_accuracy: 0.6580\n",
            "Epoch 12/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.7771 - accuracy: 0.6990\n",
            "Epoch 00012: val_loss improved from 0.85490 to 0.85097, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 18s 64ms/step - loss: 0.7771 - accuracy: 0.6988 - val_loss: 0.8510 - val_accuracy: 0.6595\n",
            "Epoch 13/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.7367 - accuracy: 0.7140\n",
            "Epoch 00013: val_loss did not improve from 0.85097\n",
            "282/282 [==============================] - 18s 63ms/step - loss: 0.7372 - accuracy: 0.7138 - val_loss: 0.8638 - val_accuracy: 0.6620\n",
            "Epoch 14/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.7076 - accuracy: 0.7304\n",
            "Epoch 00014: val_loss improved from 0.85097 to 0.84426, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 18s 64ms/step - loss: 0.7075 - accuracy: 0.7304 - val_loss: 0.8443 - val_accuracy: 0.6670\n",
            "Epoch 15/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.6807 - accuracy: 0.7364\n",
            "Epoch 00015: val_loss did not improve from 0.84426\n",
            "282/282 [==============================] - 18s 63ms/step - loss: 0.6805 - accuracy: 0.7364 - val_loss: 0.9013 - val_accuracy: 0.6505\n",
            "Epoch 16/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.6477 - accuracy: 0.7521\n",
            "Epoch 00016: val_loss improved from 0.84426 to 0.80868, saving model to best_cnn_model.h5\n",
            "282/282 [==============================] - 18s 64ms/step - loss: 0.6477 - accuracy: 0.7520 - val_loss: 0.8087 - val_accuracy: 0.6780\n",
            "Epoch 17/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.6198 - accuracy: 0.7645\n",
            "Epoch 00017: val_loss did not improve from 0.80868\n",
            "282/282 [==============================] - 18s 63ms/step - loss: 0.6199 - accuracy: 0.7645 - val_loss: 0.8530 - val_accuracy: 0.6835\n",
            "Epoch 18/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.5774 - accuracy: 0.7856\n",
            "Epoch 00018: val_loss did not improve from 0.80868\n",
            "282/282 [==============================] - 18s 63ms/step - loss: 0.5772 - accuracy: 0.7857 - val_loss: 0.8496 - val_accuracy: 0.6875\n",
            "Epoch 19/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.5484 - accuracy: 0.7912\n",
            "Epoch 00019: val_loss did not improve from 0.80868\n",
            "282/282 [==============================] - 18s 63ms/step - loss: 0.5483 - accuracy: 0.7912 - val_loss: 0.8820 - val_accuracy: 0.6730\n",
            "Epoch 20/20\n",
            "281/282 [============================>.] - ETA: 0s - loss: 0.5121 - accuracy: 0.8097\n",
            "Epoch 00020: val_loss did not improve from 0.80868\n",
            "282/282 [==============================] - 18s 63ms/step - loss: 0.5120 - accuracy: 0.8097 - val_loss: 0.9257 - val_accuracy: 0.6660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwABV9sHAclF",
        "colab_type": "text"
      },
      "source": [
        "###Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkXQP816AedQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjquMpMmAZEo",
        "colab_type": "text"
      },
      "source": [
        "###Visualize accuracy and loss over training + display best model's performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OflGd8RFsrTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-V2HVMOGRZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "compare_learning(mlp_history, lm_history, cnn_history, vgg_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kmm2fWDBtfW",
        "colab_type": "text"
      },
      "source": [
        "###How can we explain this pattern of performance across all these models?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRW9UiFbBoAK",
        "colab_type": "text"
      },
      "source": [
        "# Finished :D"
      ]
    }
  ]
}